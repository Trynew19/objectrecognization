<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #f4f4f4;
            overflow: hidden;
        }
        video, canvas {
            width: 100vw;
            height: 100vh;
            object-fit: cover;
            position: absolute;
            top: 0;
            left: 0;
        }
        button {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            padding: 12px 20px;
            font-size: 16px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            z-index: 10;
        }
    </style>
</head>
<body>
    <video id="video" autoplay muted></video>
    <canvas id="canvas"></canvas>
    <button id="switchCamera">Switch Camera</button>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const switchCameraBtn = document.getElementById("switchCamera");
        let currentFacingMode = "environment";

        async function setupCamera(facingMode = "environment") {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode }
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function detectObjects() {
            const model = await cocoSsd.load();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            async function detectFrame() {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const predictions = await model.detect(video);
                
                predictions.forEach(pred => {
                    if (pred.score > 0.5) { // Filter low confidence predictions
                        ctx.strokeStyle = "#00FF00";
                        ctx.lineWidth = 2;
                        ctx.strokeRect(pred.bbox[0], pred.bbox[1], pred.bbox[2], pred.bbox[3]);
                        
                        ctx.fillStyle = "rgba(0, 255, 0, 0.8)";
                        ctx.font = "16px Arial";
                        ctx.fillRect(pred.bbox[0], pred.bbox[1] - 25, ctx.measureText(pred.class).width + 40, 25);
                        
                        ctx.fillStyle = "#000000";
                        ctx.fillText(`${pred.class} (${Math.round(pred.score * 100)}%)`, pred.bbox[0] + 5, pred.bbox[1] - 5);
                    }
                });
                requestAnimationFrame(detectFrame);
            }
            detectFrame();
        }

        switchCameraBtn.addEventListener("click", async () => {
            currentFacingMode = currentFacingMode === "user" ? "environment" : "user";
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: currentFacingMode }
            });
            video.srcObject = stream;
        });

        setupCamera().then(detectObjects);
    </script>
</body>
</html>
